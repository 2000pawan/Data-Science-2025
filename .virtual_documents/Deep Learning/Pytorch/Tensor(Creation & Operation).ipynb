import torch
print((torch.__version__))


if torch.cuda.is_available():
  print("GPU is available")
  print(f"Using GPU: {torch.cuda.get_device_name(0)}")
else:
  print("GPU is not available")





# Using empty:-  returns a tensor of the specified shape without initializing its values. The values in the returned tensor are whatever happens to already exist at that memory location (i.e., random "garbage" values).
a=torch.empty(2,3)
a


# Check type
type(a)


# Using Zeros:- All values set to 0
torch.zeros(2,3)


# Using Ones:- All values set to 1
torch.ones(2,3)


# Using of rand:- Returns a 2√ó3 tensor with random values uniformly sampled from [0, 1).
torch.rand(2,3)





# Manual Seed:- Sets the seed for generating random numbers to ensure reproducibility.
torch.manual_seed(100)
torch.rand(2,3)


# Using Tensor:-  constructs a tensor from a Python list or nested list (or NumPy array).
torch.tensor([[1,2,3],[4,5,6]])


# Other ways to create a Tensor

# Arange:- Creates a 1D tensor with values from 0 to 8, spaced by 2.
print("Using arange:-\n",torch.arange(0,10,2))

# Using Linspace:- Creates a 1D tensor of 10 evenly spaced values between 0 and 10 (inclusive).
print("Using linspace:- \n",torch.linspace(0,10,10))

# Using eye:- Creates a 5√ó5 identity matrix (diagonal = 1, others = 0).
print("Using eye:- \n",torch.eye(5))

# Using Full:- Creates a 2√ó3 tensor filled with the constant value 5
print("Using Full:- \n",torch.full((2,3),5))





x=torch.tensor([[1,2,3],[4,5,6]])
x


x.shape


# Using empty_like:- Creates a new tensor with the same shape and type as x, but with uninitialized (garbage) values.
torch.empty_like(x)


torch.zeros_like(x)


torch.ones_like(x)


# Attempts to create a tensor with random values (uniformly in [0, 1)) matching the shape of x, but throws an error if x has integer type (like Long), because random floats cannot be stored in integer tensors.
# Because rand generate by default float value so its give error
torch.rand_like(x,dtype=torch.float32)






# Find Data Type
x.dtype


# Assign Data Type
torch.tensor([[1,2,3],[4,5,6]],dtype=torch.float32)


torch.tensor([1.0,2.0,3.0],dtype=torch.int32)


# Using to() to change data type
x.to(dtype=torch.float32)











x=torch.rand(2,2)
x


# Addition
print("Adding 2 to x:-\n",x+2)

# Substraction
print("Subtract 2 to x:-\n",x-2)

# Multiplication
print("Multiply 2 to x:-\n",x*2)

# Division
print("Divide 2 to x:-\n",x/2)

# int division
print("int divide 2 to x:-\n",(x*100)//2)

# Mod
print("Mod 2 to x:-\n",((x*100)//2)%2)

# Power
print("Power 2 to x:-\n",x**2)






a=torch.rand(2,3)
b=torch.rand(2,3)

print(a)
print(b)


# Addition of two tensor
print("Adding two tensor a & b:-\n",a+b)

# Substraction
print("Subtract two tensor a & b:-\n",a-b)

# Multiplication
print("Multiply teo tensor a & b:-\n",a*b)

# Division
print("Divide two tenor a & b:-\n",a/b)

# Mod
print("Mod of two tensor a & b:-\n",a%b)

# Power
print("Power of two tensor a & b:-\n",a**b)



c=torch.tensor([1,-2,-5,6])
c


# abs value
abs(c)  # Pythono built-in method
torch.abs(c) # torch method


# convert negative number
torch.neg(c) # negative become positive and p[ositive become negative


d=torch.tensor([1.5,2.6,3.2,4.1])
d


# round off number Rounds each element of d to the nearest integer (rounds .5 to even).
torch.round(d)


# Ceil Rounds each element of d upward to the nearest integer.
torch.ceil(d)


# floor Rounds each element of tensor d downward to the nearest integer (i.e., the largest integer ‚â§ the value).
torch.floor(d)


# clamp Clamps all elements in tensor d to lie within the range [2, 3], replacing values below 2 with 2 and above 3 with 3.
torch.clamp(d,min=2,max=3)





e=torch.randint(size=(2,3),low=0,high=10,dtype=torch.float32)
e


# sum
print("Sum:- \n",torch.sum(e))

# sum along column
print("Sum:- \n",torch.sum(e,dim=0))

# sum along rows
print("Sum:- \n",torch.sum(e,dim=1))


# mean
print('Mean:-\n',torch.mean(e))

# mean along column
print('Mean:-\n',torch.mean(e,dim=0))


# median
torch.median(e)


# Max
print("Max:-\n",torch.max(e))

# Min
print('Min:-\n',torch.min(e))


# Product
torch.prod(e)


# Standard Deviations
torch.std(e)


# Variance
torch.var(e)


# argmax give position of maximum value
torch.argmax(e)


# argmin give position of min value
torch.argmin(e)





f=torch.randint(size=(2,3),low=0,high=10,dtype=torch.float32)
g=torch.randint(size=(3,2),low=0,high=10,dtype=torch.float32)

print(f)
print(g)


# Matrix Multiplication
torch.matmul(f,g)


vector1=torch.tensor([1,2])
vector2=torch.tensor([3,4])

# dot product
torch.dot(vector1,vector2)


# Transpose Returns a new tensor with dimensions 0 and 1 swapped (i.e., transposes rows and columns of 2D tensor f).
print(f)
torch.transpose(f,1,0)


h=torch.randint(size=(3,3),low=0,high=10,dtype=torch.float32)
h


# Determinant
torch.det(h)


# Inverse Returns the inverse of a square, non-singular matrix h (i.e., a matrix such that h √ó h‚Åª¬π = I).
torch.inverse(h)





i=torch.randint(size=(2,3),low=0,high=10,dtype=torch.float32)
j=torch.randint(size=(2,3),low=0,high=10,dtype=torch.float32)

print(i)
print(j)


# greater than
print(i > j)
# less than
print(i < j)
# equal to
print(i == j)
# not equal to
print(i != j)
# greater than equal to
print(i<=j)
# less than equal to
print(i>=j)





k=torch.randint(size=(2,3),low=0,high=10,dtype=torch.float32)
k


# Log
torch.log(k)


# Exp
torch.exp(k)


# SQRT
torch.sqrt(k)


# Sigmoid
torch.sigmoid(k)


# Softmax Applies the softmax function along dimension 0, turning values into probabilities that sum to 1 along that dimension.
torch.softmax(k,dim=0)


# Relu
torch.relu(k)





m=torch.rand(2,3)
n=torch.rand(2,3)
print(m)
print(n)


# # Performs in-place addition of tensor n to tensor m, modifying m directly without creating a new tensor.

# üîÅ Difference:
# m.add(n) ‚Üí returns a new tensor
# m.add_(n) ‚Üí updates m in-place
m.add_(n)


m


n








a=torch.rand(2,3)
a


b=a


b


a[0][0]=7
a


b


id(a)


id(b)


c=a.clone()
c


a[0][0]=12
a


c


id(a)


id(c)



