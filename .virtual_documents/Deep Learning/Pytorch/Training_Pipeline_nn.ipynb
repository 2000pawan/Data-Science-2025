





# pip install torchinfo


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.datasets import load_breast_cancer
import torch 
import torch.nn as nn
from torchinfo import summary





# Create Model Class with simple neural network without hidden layers.
class Model(nn.Module):
    def __init__(self, num_features):
        
        super().__init__()
        
        self.linear=nn.Linear(num_features,1)
        self.sigmoid=nn.Sigmoid()
    
# Forward Pass
    def forward(self,features):
        
        out=self.linear(features)
        out=self.sigmoid(out)
        
        return out

# Create fake dataset.
features=torch.rand(10,5)

# Create Model object.
model=Model(features.shape[1])

# Call forward pass.
#model.forward(features) # pytorch used magic method __call__ and override  this and when we call its autometic trigger.
model(features)

# show model weights and bias.
print(model.linear.weight)
print(model.linear.bias)

print(summary(model,input_size=(10,5)))


# Create Model Class with simple neural network with hidden layers.
class Model(nn.Module):
    def __init__(self, num_features):
        
        super().__init__()
        
        self.linear1=nn.Linear(num_features,3)
        self.relu=nn.ReLU()
        self.linear2=nn.Linear(3,1)
        self.sigmoid=nn.Sigmoid()
    
# Forward Pass
    def forward(self,features):
        
        out=self.linear1(features)
        out=self.relu(out)
        out=self.linear2(out)
        out=self.sigmoid(out)
        
        return out

# Create fake dataset.
features=torch.rand(10,5)

# Create Model object.
model=Model(features.shape[1])

# Call forward pass.
#model.forward(features) # pytorch used magic method __call__ and override  this and when we call its autometic trigger.
model(features)

# show model weights and bias.
print(model.linear1.weight)
print(model.linear1.bias)
print(model.linear2.weight)
print(model.linear2.bias)

print(summary(model,input_size=(10,5)))


# Create Model Class with simple neural network with hidden layers and use sequential container.
class Model(nn.Module):
    def __init__(self, num_features):
        
        super().__init__()
        
        self.network=nn.Sequential(nn.Linear(num_features,3),
            nn.ReLU(),
            nn.Linear(3,1),
            nn.Sigmoid()
        )
    
# Forward Pass
    def forward(self,features):
        
        out=self.network(features)  
        return out

# Create fake dataset.
features=torch.rand(10,5)

# Create Model object.
model=Model(features.shape[1])

# Call forward pass.
#model.forward(features) # pytorch used magic method __call__ and override  this and when we call its autometic trigger.
model(features)

# Iterate through each layer and print its parameters
for name, param in model.named_parameters():
    if 'weight' in name:
        print(f'Layer: {name} | Size: {param.size()} | Values: {param}\n')
    elif 'bias' in name:
        print(f'Layer: {name} | Size: {param.size()} | Values: {param}\n')

print(summary(model,input_size=(10,5)))





df = load_breast_cancer()
X = df.data
y = df.target

# Train Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)

# Scaling
sc = StandardScaler()
X_train_new = sc.fit_transform(X_train)
X_test_new = sc.transform(X_test)

# Encoding target
lenc = LabelEncoder()
y_train_new = lenc.fit_transform(y_train)
y_test_new = lenc.transform(y_test)





# Numpy array to tensor 
X_train = torch.from_numpy(X_train_new).float()
X_test = torch.from_numpy(X_test_new).float()
y_train = torch.from_numpy(y_train_new).float()
y_test = torch.from_numpy(y_test_new).float()





# Create Model.
class MySimpleModel(nn.Module):
    def __init__(self, num_features):
        super().__init__()
        self.network=nn.Sequential(nn.Linear(num_features,20),
                                  nn.ReLU(),
                                  nn.Linear(20,15),
                                  nn.ReLU(),
                                  nn.Linear(15,10),
                                  nn.ReLU(),
                                  nn.Linear(10,1),
                                  nn.Sigmoid()
                                  )
    def forward(self,features):
        out=self.network(features)
        return out





learning_rate=0.1
epochs=25





# Define Loss Function.
loss_func=nn.BCELoss()

# Create Model Object.
model= MySimpleModel(X_train.shape[1])

# Define optimizer.
optimizer= torch.optim.SGD(model.parameters(), lr=learning_rate)

# define loop
for epoch in range(epochs):

    # forward pass
    y_pred=model(X_train)
    
    # Loss calculation
    # view() is used to reshape a tensor without changing its data. 
    # The -1 tells PyTorch: "I donâ€™t know what this dimension should be,
    # so calculate it automatically based on the other dimensions and total number of elements.""""
    loss=loss_func(y_pred, y_train.view(-1,1))
    
    # Clear gradients 
    optimizer.zero_grad()

    # Backward pass
    loss.backward()
    
    #parameters update
    optimizer.step()
    
    # print loss in each epoch
    print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')

    





# model evaluation
with torch.no_grad():
  y_pred = model.forward(X_test)
  y_pred = (y_pred > 0.5).float()
  accuracy = (y_pred == y_test).float().mean()
  print(f'Accuracy: {accuracy.item()}')


print(summary(model, input_size=(X_train.shape[0], X_train.shape[1])))



