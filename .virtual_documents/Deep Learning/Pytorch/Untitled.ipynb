





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
from torch.utils.data import Dataset,DataLoader
import torch.optim as optim
from torchinfo import summary

# Set random seeds for reproducibility
torch.manual_seed(42)


df=pd.read_csv('fmnist_small.csv')
df.shape


# Create a 4*4 grid of images
fig,axes=plt.subplots(4,4,figsize=(8,8))
fig.suptitle("First 16 Images", fontsize=18)

# plot the first 16 images from the dataset
for i, ax in enumerate(axes.flat):
    img=df.iloc[i,1:].values.reshape(28,28)
    ax.imshow(img)
    ax.axis('off')
    ax.set_title(f"Label: {df.iloc[i,0]}")
plt.tight_layout(rect=[0,0,1,0.96])
plt.show()





# Data extract. 
X=df.iloc[:,1:].values
y=df.iloc[:,0].values

# Data Split.
X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.20,random_state=42)

# Scaling in a range.
X_train=X_train/255.0
X_test=X_test/255.0





class CustomDataset(Dataset):
    def __init__(self,features,labels):
        self.features = torch.tensor(features, dtype=torch.float32)
        self.labels = torch.tensor(labels, dtype=torch.long)
    
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self,idx):
        return self.features[idx], self.labels[idx]

train_dataset=CustomDataset(X_train,y_train)
test_dataset=CustomDataset(X_test,y_test)

# Data Loader

train_loader=DataLoader(train_dataset,batch_size=32,shuffle=True)
test_loader=DataLoader(test_dataset,batch_size=32,shuffle=False)





class Mnist(nn.Module):
    def __init__(self,num_features):
        super().__init__()
        self.network=nn.Sequential(
            nn.Linear(num_features,256),
            nn.ReLU(),
            nn.Linear(256,128),
            nn.ReLU(),
            nn.Linear(128,64),
            nn.ReLU(),
            nn.Linear(64,32),
            nn.ReLU(),
            nn.Linear(32,10),
        )
    # Forward Pass
    def forward(self,features):
        out=self.network(features)
        return out





epochs=200
learning_rate=0.001





model=Mnist(X_train.shape[1])

# Loss function
criterion =nn.CrossEntropyLoss()

# Optimizer
optimizer=optim.SGD(model.parameters(),lr=learning_rate)





for epoch in range(epochs):
    total_epoch_loss=0
    for batch_features,batch_labels in train_loader:

        # Forward Pass
        y_pred=model(batch_features)
        
        # Loss Calculate
        loss=criterion(y_pred,batch_labels)

        # back Pass
        optimizer.zero_grad()
        loss.backward()
        
        # update Weight and bias
        optimizer.step()
        
        total_epoch_loss=total_epoch_loss + loss.item()
    
    avg_loss=total_epoch_loss/len(train_loader)
    print(f"Epoch: {epoch + 1}, Loss: {avg_loss}")





# set model to eval mode
model.eval()


total=0
correct=0

with torch.no_grad():
      for batch_features, batch_labels in test_loader:
          outputs = model(batch_features)
          _, predicted = torch.max(outputs, 1)
          total = total + batch_labels.shape[0]
          correct = correct + (predicted == batch_labels).sum().item()

print(correct/total)


summary(model.parameters(),input_size=(784,256))



