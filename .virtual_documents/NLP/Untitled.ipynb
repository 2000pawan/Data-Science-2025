


import pandas as pd
import re
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS,CountVectorizer,TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier


doc1='f5o@od is # good & good!'
doc2='& Food # is * tasty'
doc3='Quality is Good'
doc4='food is not good'
doc5='servi89ce is Poor poor means very poor'
doc6='it is to_o costly'
doc7='che^ap quality'
corpus=[doc1,doc2,doc3,doc4,doc5,doc6,doc7]
target=['pos','pos','pos','neg','neg','neg','neg']
print(corpus)





def cleaning(doc):
    doc=doc.lower()
    doc=re.sub('[^a-z ]','',doc)
    sp=list(ENGLISH_STOP_WORDS)
    sp.remove('not')
    wordslist=doc.split()
    newdoc=''
    for word in wordslist:
        if word not in sp:
            newdoc=newdoc+word+' '
    return newdoc.strip()

corpus1=list(map(cleaning,corpus))
cv=CountVectorizer()
X=cv.fit_transform(corpus1)
print(cv.get_feature_names_out())
X1=X.toarray()
model=RandomForestClassifier()
model.fit(X1,target)


sample1='Food quality is not good$'
sample2='awesome food'
corpus=[sample1,sample2]
corpus1=list(map(cleaning,corpus))
corpus2=cv.transform(corpus1).toarray()
print(model.predict(corpus2))
print(model.predict_proba(corpus2))


corpus=[doc1,doc2,doc3,doc4,doc5,doc6,doc7]
corpus1=list(map(cleaning,corpus))
cv=CountVectorizer(max_features=None,min_df=1,max_df=2)
X=cv.fit_transform(corpus1)
print(cv.get_feature_names_out())


corpus=[doc1,doc2,doc3,doc4,doc5,doc6,doc7]
corpus1=list(map(cleaning,corpus))
cv=CountVectorizer(ngram_range=(1,2))
X=cv.fit_transform(corpus1)
print(cv.get_feature_names_out())


corpus=[doc1,doc2,doc3,doc4,doc5,doc6,doc7]
corpus1=list(map(cleaning,corpus))
cv=CountVectorizer(binary=True)
X=cv.fit_transform(corpus1).toarray()
print(X)


corpus=[doc1,doc2,doc3,doc4,doc5,doc6,doc7]
cv=CountVectorizer(lowercase=True,stop_words=sp)
X=cv.fit_transform(corpus)
print(cv.get_feature_names_out())


corpus=[doc1,doc2,doc3,doc4,doc5,doc6,doc7]
corpus1=list(map(cleaning,corpus))
tf=TfidfVectorizer()
X=tf.fit_transform(corpus1)
print(cv.get_feature_names_out())
print(X.toarray())


corpus=[doc1,doc2,doc3,doc4,doc5,doc6,doc7]
corpus1=list(map(cleaning,corpus))
cv=CountVectorizer()
X=cv.fit_transform(corpus1)
print(cv.get_feature_names_out())


print(X.toarray())


print(corpus1)





import math
tf=1
df=3
idf=math.log((1+7)/(1+df))+1
score=tf*idf
score1=score**2


tf2=2
score2=tf2*idf
score3=score2**2


new_score=score1+score3
new_score


sqrt=math.sqrt(new_score)
sqrt


ns=score/sqrt
ns1=score2/sqrt
print(ns)  # Food normalize score
print(ns1)  # Good normalize score


corpus=[doc1,doc2,doc3,doc4,doc5,doc6,doc7]
corpus1=list(map(cleaning,corpus))
tf=TfidfVectorizer(binary=True)
X=tf.fit_transform(corpus1)
print(cv.get_feature_names_out())
print(X.toarray())





df=pd.read_csv('G:/dataset/sentiment/Restaurant_Reviews.txt',sep='\t')
df


corpus=df['Review']
target=df['Liked']


corpus1=list(map(cleaning,corpus))
cv=CountVectorizer()
X=cv.fit_transform(corpus1)
print(cv.get_feature_names_out())
print(len(cv.get_feature_names_out()))
X1=X.toarray()


model=RandomForestClassifier(n_estimators=100)
model.fit(X1,target)


sample1='Food quality is not good$'
sample2='awesome food'
corpus_test=[sample1,sample2]
corpus_test_new=list(map(cleaning,corpus_test))
X_test=cv.transform(corpus_test_new)
print(model.predict(X_test))
print(model.predict_proba(X_test))


sample=input("Enter Your Valuable Feedback:- /n")



